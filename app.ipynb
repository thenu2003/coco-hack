{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Failed to capture frame\n",
      "Error occurred while closing the OpenCV windows: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1266: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from time import sleep\n",
    "import json\n",
    "\n",
    "model_path = r'guru.h5'\n",
    "try:\n",
    "    model = load_model(model_path)\n",
    "except Exception as e:\n",
    "    print(\"Error loading the model:\", e)\n",
    "    exit(1)\n",
    "\n",
    "classes = ['coco', 'coonut']\n",
    "timer = 5\n",
    "prev_detected_class = None\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Failed to open camera\")\n",
    "    exit(1)\n",
    "\n",
    "# Create a placeholder for display_frame outside the loop\n",
    "display_frame = None\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Error: Failed to capture frame\")\n",
    "        break\n",
    "\n",
    "    timer -= 1\n",
    "\n",
    "    if timer == 0:\n",
    "        timer = 5\n",
    "\n",
    "        # Create a copy of the frame for display\n",
    "        display_frame = frame.copy()\n",
    "\n",
    "        frame = cv2.resize(frame, (224, 224))\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = frame / 255.0\n",
    "        frame = np.expand_dims(frame, axis=0)\n",
    "\n",
    "        try:\n",
    "            predictions = model.predict(frame)\n",
    "            predicted_class_index = np.argmax(predictions)\n",
    "            predicted_class = classes[predicted_class_index]\n",
    "\n",
    "            if predicted_class != prev_detected_class:\n",
    "                if predicted_class in ['coco', 'coonut']:\n",
    "                    print(json.dumps({\"Detected\": predicted_class}))\n",
    "                else:\n",
    "                    print(\"Detected:\", predicted_class)\n",
    "                prev_detected_class = predicted_class\n",
    "        except Exception as e:\n",
    "            print(\"Error during prediction:\", e)\n",
    "\n",
    "    # Display the copy of the frame if it's defined\n",
    "    if display_frame is not None and display_frame.shape[0] > 0 and display_frame.shape[1] > 0 and display_frame.shape[2] == 3:\n",
    "        cv2.imshow('Frame', display_frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the camera and close the window\n",
    "cap.release()\n",
    "try:\n",
    "    cv2.destroyAllWindows()\n",
    "except Exception as e:\n",
    "    print(\"Error occurred while closing the OpenCV windows:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load image: D:\\hack-coco\\coconut\\train\\coconut\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 20s 673ms/step - loss: 1.0771 - accuracy: 0.5750 - val_loss: 10.6722 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 16s 630ms/step - loss: 0.5905 - accuracy: 0.7063 - val_loss: 2.8499 - val_accuracy: 0.0000e+00 - lr: 9.0000e-04\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 16s 633ms/step - loss: 0.4115 - accuracy: 0.8425 - val_loss: 0.6122 - val_accuracy: 0.6600 - lr: 8.1000e-04\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 16s 628ms/step - loss: 0.2673 - accuracy: 0.9187 - val_loss: 0.2764 - val_accuracy: 0.9400 - lr: 7.2900e-04\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 16s 644ms/step - loss: 0.2091 - accuracy: 0.9312 - val_loss: 0.1541 - val_accuracy: 0.9900 - lr: 6.5610e-04\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 16s 624ms/step - loss: 0.1370 - accuracy: 0.9700 - val_loss: 0.1148 - val_accuracy: 1.0000 - lr: 5.9049e-04\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 16s 624ms/step - loss: 0.1033 - accuracy: 0.9862 - val_loss: 0.0997 - val_accuracy: 1.0000 - lr: 5.3144e-04\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 16s 626ms/step - loss: 0.0696 - accuracy: 0.9937 - val_loss: 0.0480 - val_accuracy: 1.0000 - lr: 4.7830e-04\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 16s 643ms/step - loss: 0.0563 - accuracy: 0.9950 - val_loss: 0.0369 - val_accuracy: 1.0000 - lr: 4.3047e-04\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 16s 637ms/step - loss: 0.0524 - accuracy: 0.9937 - val_loss: 0.0719 - val_accuracy: 1.0000 - lr: 3.8742e-04\n",
      "4/4 [==============================] - 1s 179ms/step - loss: 0.0719 - accuracy: 1.0000\n",
      "Test Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping\n",
    "\n",
    "# Path to your dataset\n",
    "dataset_path = r\"D:\\hack-coco\\coconut\"\n",
    "\n",
    "# Assuming your dataset is organized in folders with class names\n",
    "classes = ['coconut',\"\"]\n",
    "\n",
    "# Load dataset\n",
    "def load_dataset():\n",
    "    X, y = [], []\n",
    "    for i, class_name in enumerate(classes):\n",
    "        class_path = os.path.join(dataset_path, 'train', class_name)\n",
    "        for image_name in os.listdir(class_path):\n",
    "            image_path = os.path.join(class_path, image_name)\n",
    "            try:\n",
    "                image = cv2.imread(image_path)\n",
    "                if image is not None:\n",
    "                    image = cv2.resize(image, (224, 224))\n",
    "                    X.append(image)\n",
    "                    y.append(i)  # Label for the class\n",
    "                else:\n",
    "                    print(f\"Failed to load image: {image_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {image_path}: {str(e)}\")\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y\n",
    "\n",
    "# Load and preprocess dataset\n",
    "X, y = load_dataset()\n",
    "\n",
    "# Split dataset into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Create data generators with increased data augmentation and noise for training and validation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    brightness_range=[0.7, 1.3],  # Adjust brightness randomly\n",
    "    preprocessing_function=lambda x: x + np.random.normal(0, 0.1, x.shape)  # Add random noise\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=32)\n",
    "val_generator = val_datagen.flow(X_val, y_val, batch_size=32)\n",
    "\n",
    "# Create test data generator\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow(X_test, y_test, batch_size=32, shuffle=False)\n",
    "\n",
    "# Use transfer learning with MobileNetV2 as the base model\n",
    "base_model = MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom classification head with additional regularization techniques\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)  # Dropout for regularization\n",
    "predictions = Dense(len(classes), activation='softmax')(x)\n",
    "\n",
    "# Create model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile model with additional regularization\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Learning rate schedule function\n",
    "def lr_schedule(epoch):\n",
    "    return 0.001 * (0.9 ** epoch)\n",
    "\n",
    "# Learning rate scheduler\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "\n",
    "# Train the model with learning rate scheduling, early stopping, and additional regularization\n",
    "model.fit(train_generator, epochs=10, validation_data=val_generator, callbacks=[lr_scheduler, early_stopping])\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n",
    "\n",
    "# Save the trained model\n",
    "model.save('guru1.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
