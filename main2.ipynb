{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Failed to capture frame\n",
      "Error occurred while closing the OpenCV windows: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1266: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from time import sleep\n",
    "import json\n",
    "\n",
    "model_path = r'guru.h5'\n",
    "try:\n",
    "    model = load_model(model_path)\n",
    "except Exception as e:\n",
    "    print(\"Error loading the model:\", e)\n",
    "    exit(1)\n",
    "\n",
    "classes = ['coco', 'coonut']\n",
    "timer = 5\n",
    "prev_detected_class = None\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Failed to open camera\")\n",
    "    exit(1)\n",
    "\n",
    "# Create a placeholder for display_frame outside the loop\n",
    "display_frame = None\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Error: Failed to capture frame\")\n",
    "        break\n",
    "\n",
    "    timer -= 1\n",
    "\n",
    "    if timer == 0:\n",
    "        timer = 5\n",
    "\n",
    "        # Create a copy of the frame for display\n",
    "        display_frame = frame.copy()\n",
    "\n",
    "        frame = cv2.resize(frame, (224, 224))\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = frame / 255.0\n",
    "        frame = np.expand_dims(frame, axis=0)\n",
    "\n",
    "        try:\n",
    "            predictions = model.predict(frame)\n",
    "            predicted_class_index = np.argmax(predictions)\n",
    "            predicted_class = classes[predicted_class_index]\n",
    "\n",
    "            if predicted_class != prev_detected_class:\n",
    "                if predicted_class in ['coco', 'coonut']:\n",
    "                    print(json.dumps({\"Detected\": predicted_class}))\n",
    "                else:\n",
    "                    print(\"Detected:\", predicted_class)\n",
    "                prev_detected_class = predicted_class\n",
    "        except Exception as e:\n",
    "            print(\"Error during prediction:\", e)\n",
    "\n",
    "    # Display the copy of the frame if it's defined\n",
    "    if display_frame is not None and display_frame.shape[0] > 0 and display_frame.shape[1] > 0 and display_frame.shape[2] == 3:\n",
    "        cv2.imshow('Frame', display_frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the camera and close the window\n",
    "cap.release()\n",
    "try:\n",
    "    cv2.destroyAllWindows()\n",
    "except Exception as e:\n",
    "    print(\"Error occurred while closing the OpenCV windows:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Thenmozhi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Thenmozhi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Thenmozhi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From c:\\Users\\Thenmozhi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Thenmozhi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "64/64 [==============================] - 60s 791ms/step - loss: 0.2925 - accuracy: 0.9009 - val_loss: 0.1086 - val_accuracy: 0.9688 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "64/64 [==============================] - 52s 805ms/step - loss: 0.0586 - accuracy: 0.9868 - val_loss: 0.0335 - val_accuracy: 0.9922 - lr: 9.0000e-04\n",
      "Epoch 3/50\n",
      "64/64 [==============================] - 56s 866ms/step - loss: 0.0382 - accuracy: 0.9941 - val_loss: 0.0224 - val_accuracy: 0.9922 - lr: 8.1000e-04\n",
      "Epoch 4/50\n",
      "64/64 [==============================] - 53s 828ms/step - loss: 0.0189 - accuracy: 0.9951 - val_loss: 0.0053 - val_accuracy: 1.0000 - lr: 7.2900e-04\n",
      "Epoch 5/50\n",
      "64/64 [==============================] - 52s 810ms/step - loss: 0.0235 - accuracy: 0.9961 - val_loss: 0.0050 - val_accuracy: 1.0000 - lr: 6.5610e-04\n",
      "Epoch 6/50\n",
      "64/64 [==============================] - 50s 781ms/step - loss: 0.0091 - accuracy: 0.9980 - val_loss: 0.0044 - val_accuracy: 0.9961 - lr: 5.9049e-04\n",
      "Epoch 7/50\n",
      "64/64 [==============================] - 49s 763ms/step - loss: 0.0152 - accuracy: 0.9980 - val_loss: 0.0025 - val_accuracy: 1.0000 - lr: 5.3144e-04\n",
      "Epoch 8/50\n",
      "64/64 [==============================] - 50s 779ms/step - loss: 0.0146 - accuracy: 0.9966 - val_loss: 0.0026 - val_accuracy: 1.0000 - lr: 4.7830e-04\n",
      "Epoch 9/50\n",
      "64/64 [==============================] - 49s 769ms/step - loss: 0.0134 - accuracy: 0.9971 - val_loss: 0.0013 - val_accuracy: 1.0000 - lr: 4.3047e-04\n",
      "Epoch 10/50\n",
      "64/64 [==============================] - 51s 792ms/step - loss: 0.0110 - accuracy: 0.9976 - val_loss: 0.0034 - val_accuracy: 1.0000 - lr: 3.8742e-04\n",
      "Epoch 11/50\n",
      "64/64 [==============================] - 49s 761ms/step - loss: 0.0112 - accuracy: 0.9971 - val_loss: 9.3431e-04 - val_accuracy: 1.0000 - lr: 3.4868e-04\n",
      "Epoch 12/50\n",
      "64/64 [==============================] - 51s 788ms/step - loss: 0.0085 - accuracy: 0.9990 - val_loss: 8.3741e-04 - val_accuracy: 1.0000 - lr: 3.1381e-04\n",
      "Epoch 13/50\n",
      "64/64 [==============================] - 50s 780ms/step - loss: 0.0066 - accuracy: 0.9990 - val_loss: 7.6927e-04 - val_accuracy: 1.0000 - lr: 2.8243e-04\n",
      "Epoch 14/50\n",
      "64/64 [==============================] - 50s 776ms/step - loss: 0.0055 - accuracy: 0.9995 - val_loss: 6.7834e-04 - val_accuracy: 1.0000 - lr: 2.5419e-04\n",
      "Epoch 15/50\n",
      "64/64 [==============================] - 50s 775ms/step - loss: 0.0052 - accuracy: 0.9990 - val_loss: 6.8279e-04 - val_accuracy: 1.0000 - lr: 2.2877e-04\n",
      "Epoch 16/50\n",
      "64/64 [==============================] - 48s 753ms/step - loss: 0.0112 - accuracy: 0.9966 - val_loss: 5.5231e-04 - val_accuracy: 1.0000 - lr: 2.0589e-04\n",
      "Epoch 17/50\n",
      "64/64 [==============================] - 49s 759ms/step - loss: 0.0092 - accuracy: 0.9976 - val_loss: 6.0923e-04 - val_accuracy: 1.0000 - lr: 1.8530e-04\n",
      "Epoch 18/50\n",
      "64/64 [==============================] - 53s 820ms/step - loss: 0.0037 - accuracy: 0.9995 - val_loss: 5.8266e-04 - val_accuracy: 1.0000 - lr: 1.6677e-04\n",
      "Epoch 19/50\n",
      "64/64 [==============================] - 49s 766ms/step - loss: 0.0041 - accuracy: 0.9995 - val_loss: 4.9275e-04 - val_accuracy: 1.0000 - lr: 1.5009e-04\n",
      "Epoch 20/50\n",
      "64/64 [==============================] - 50s 775ms/step - loss: 0.0053 - accuracy: 0.9990 - val_loss: 4.6313e-04 - val_accuracy: 1.0000 - lr: 1.3509e-04\n",
      "Epoch 21/50\n",
      "64/64 [==============================] - 52s 806ms/step - loss: 0.0030 - accuracy: 0.9985 - val_loss: 4.4083e-04 - val_accuracy: 1.0000 - lr: 1.2158e-04\n",
      "Epoch 22/50\n",
      "64/64 [==============================] - 49s 769ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 3.7999e-04 - val_accuracy: 1.0000 - lr: 1.0942e-04\n",
      "Epoch 23/50\n",
      "64/64 [==============================] - 49s 762ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 3.3042e-04 - val_accuracy: 1.0000 - lr: 9.8477e-05\n",
      "Epoch 24/50\n",
      "64/64 [==============================] - 48s 755ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 3.5148e-04 - val_accuracy: 1.0000 - lr: 8.8629e-05\n",
      "Epoch 25/50\n",
      "64/64 [==============================] - 49s 764ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 3.5466e-04 - val_accuracy: 1.0000 - lr: 7.9766e-05\n",
      "Epoch 26/50\n",
      "64/64 [==============================] - 48s 743ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 3.8279e-04 - val_accuracy: 1.0000 - lr: 7.1790e-05\n",
      "Epoch 27/50\n",
      "64/64 [==============================] - 48s 757ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 3.5492e-04 - val_accuracy: 1.0000 - lr: 6.4611e-05\n",
      "Epoch 28/50\n",
      "64/64 [==============================] - 48s 751ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 3.2528e-04 - val_accuracy: 1.0000 - lr: 5.8150e-05\n",
      "Epoch 29/50\n",
      "64/64 [==============================] - 48s 756ms/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 3.5161e-04 - val_accuracy: 1.0000 - lr: 5.2335e-05\n",
      "Epoch 30/50\n",
      "64/64 [==============================] - 48s 754ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 3.2594e-04 - val_accuracy: 1.0000 - lr: 4.7101e-05\n",
      "Epoch 31/50\n",
      "64/64 [==============================] - 50s 772ms/step - loss: 0.0024 - accuracy: 0.9990 - val_loss: 2.9616e-04 - val_accuracy: 1.0000 - lr: 4.2391e-05\n",
      "Epoch 32/50\n",
      "64/64 [==============================] - 49s 772ms/step - loss: 0.0053 - accuracy: 0.9985 - val_loss: 2.9907e-04 - val_accuracy: 1.0000 - lr: 3.8152e-05\n",
      "Epoch 33/50\n",
      "64/64 [==============================] - 48s 754ms/step - loss: 0.0084 - accuracy: 0.9971 - val_loss: 2.7763e-04 - val_accuracy: 1.0000 - lr: 3.4337e-05\n",
      "Epoch 34/50\n",
      "64/64 [==============================] - 48s 742ms/step - loss: 0.0101 - accuracy: 0.9976 - val_loss: 2.8984e-04 - val_accuracy: 1.0000 - lr: 3.0903e-05\n",
      "Epoch 35/50\n",
      "64/64 [==============================] - 48s 755ms/step - loss: 0.0057 - accuracy: 0.9980 - val_loss: 2.8279e-04 - val_accuracy: 1.0000 - lr: 2.7813e-05\n",
      "Epoch 36/50\n",
      "64/64 [==============================] - 48s 747ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 2.7427e-04 - val_accuracy: 1.0000 - lr: 2.5032e-05\n",
      "Epoch 37/50\n",
      "64/64 [==============================] - 53s 831ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 2.7375e-04 - val_accuracy: 1.0000 - lr: 2.2528e-05\n",
      "Epoch 38/50\n",
      "64/64 [==============================] - 53s 823ms/step - loss: 0.0055 - accuracy: 0.9980 - val_loss: 2.6444e-04 - val_accuracy: 1.0000 - lr: 2.0276e-05\n",
      "Epoch 39/50\n",
      "64/64 [==============================] - 48s 749ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 2.6651e-04 - val_accuracy: 1.0000 - lr: 1.8248e-05\n",
      "Epoch 40/50\n",
      "64/64 [==============================] - 48s 744ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 2.4877e-04 - val_accuracy: 1.0000 - lr: 1.6423e-05\n",
      "Epoch 41/50\n",
      "64/64 [==============================] - 51s 790ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.5276e-04 - val_accuracy: 1.0000 - lr: 1.4781e-05\n",
      "Epoch 42/50\n",
      "64/64 [==============================] - 50s 781ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.4760e-04 - val_accuracy: 1.0000 - lr: 1.3303e-05\n",
      "Epoch 43/50\n",
      "64/64 [==============================] - 49s 770ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.4450e-04 - val_accuracy: 1.0000 - lr: 1.1973e-05\n",
      "Epoch 44/50\n",
      "64/64 [==============================] - 49s 769ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.5016e-04 - val_accuracy: 1.0000 - lr: 1.0775e-05\n",
      "Epoch 45/50\n",
      "64/64 [==============================] - 48s 756ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 2.4991e-04 - val_accuracy: 1.0000 - lr: 9.6977e-06\n",
      "Epoch 46/50\n",
      "64/64 [==============================] - 47s 734ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 2.4133e-04 - val_accuracy: 1.0000 - lr: 8.7280e-06\n",
      "Epoch 47/50\n",
      "64/64 [==============================] - 49s 762ms/step - loss: 0.0067 - accuracy: 0.9990 - val_loss: 2.4382e-04 - val_accuracy: 1.0000 - lr: 7.8552e-06\n",
      "Epoch 48/50\n",
      "64/64 [==============================] - 48s 749ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 2.4324e-04 - val_accuracy: 1.0000 - lr: 7.0697e-06\n",
      "Epoch 49/50\n",
      "64/64 [==============================] - 52s 812ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.3582e-04 - val_accuracy: 1.0000 - lr: 6.3627e-06\n",
      "Epoch 50/50\n",
      "64/64 [==============================] - 49s 767ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 2.3277e-04 - val_accuracy: 1.0000 - lr: 5.7264e-06\n",
      "8/8 [==============================] - 2s 260ms/step - loss: 2.5997e-04 - accuracy: 1.0000\n",
      "Test Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Thenmozhi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping\n",
    "\n",
    "# Path to your dataset\n",
    "dataset_path = r\"D:\\projects\\coconut\\coco-detect\\data\"\n",
    "\n",
    "# Assuming your dataset is organized in folders with class names\n",
    "classes = ['coco', 'coonut']\n",
    "\n",
    "# Load dataset\n",
    "def load_dataset():\n",
    "    X, y = [], []\n",
    "    for i, class_name in enumerate(classes):\n",
    "        class_path = os.path.join(dataset_path, 'train', class_name)\n",
    "        for image_name in os.listdir(class_path):\n",
    "            image_path = os.path.join(class_path, image_name)\n",
    "            try:\n",
    "                image = cv2.imread(image_path)\n",
    "                if image is not None:\n",
    "                    image = cv2.resize(image, (224, 224))\n",
    "                    X.append(image)\n",
    "                    y.append(i)  # Label for the class\n",
    "                else:\n",
    "                    print(f\"Failed to load image: {image_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {image_path}: {str(e)}\")\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y\n",
    "\n",
    "# Load and preprocess dataset\n",
    "X, y = load_dataset()\n",
    "\n",
    "# Split dataset into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Create data generators with increased data augmentation and noise for training and validation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    brightness_range=[0.7, 1.3],  # Adjust brightness randomly\n",
    "    preprocessing_function=lambda x: x + np.random.normal(0, 0.1, x.shape)  # Add random noise\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=32)\n",
    "val_generator = val_datagen.flow(X_val, y_val, batch_size=32)\n",
    "\n",
    "# Create test data generator\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow(X_test, y_test, batch_size=32, shuffle=False)\n",
    "\n",
    "# Use transfer learning with MobileNetV2 as the base model\n",
    "base_model = MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom classification head with additional regularization techniques\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)  # Dropout for regularization\n",
    "predictions = Dense(len(classes), activation='softmax')(x)\n",
    "\n",
    "# Create model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile model with additional regularization\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Learning rate schedule function\n",
    "def lr_schedule(epoch):\n",
    "    return 0.001 * (0.9 ** epoch)\n",
    "\n",
    "# Learning rate scheduler\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "\n",
    "# Train the model with learning rate scheduling, early stopping, and additional regularization\n",
    "model.fit(train_generator, epochs=50, validation_data=val_generator, callbacks=[lr_scheduler, early_stopping])\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n",
    "\n",
    "# Save the trained model\n",
    "model.save('guru.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
